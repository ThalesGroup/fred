# Copyright Thales 2025
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Pydantic data models defining the structure of monitoring metrics.

This includes token usage details, filter results, and output formats for
numerical and categorical metric aggregations.
"""

from typing import Optional, Dict, List, Any
from pydantic import BaseModel


class TokenDetails(BaseModel):
    """
    Detailed token counts by functional category.

    Attributes:
        accepted_prediction_tokens: Tokens accepted by the model.
        rejected_prediction_tokens: Tokens discarded from prediction.
        reasoning_tokens: Tokens spent on logical or reasoning steps.
        audio_tokens: Tokens used for audio processing.
        cached_tokens: Tokens retrieved from cache.
    """
    accepted_prediction_tokens: Optional[int] = 0
    rejected_prediction_tokens: Optional[int] = 0
    reasoning_tokens: Optional[int] = 0
    audio_tokens: Optional[int] = 0
    cached_tokens: Optional[int] = 0


class TokenUsage(BaseModel):
    """
    Aggregated and detailed token counts for an inference.

    Attributes:
        completion_tokens: Tokens generated by the model.
        prompt_tokens: Tokens provided as input.
        total_tokens: Sum of prompt and completion tokens.
        completion_tokens_details: Detailed breakdown of generated tokens.
        prompt_tokens_details: Detailed breakdown of input tokens.
    """
    completion_tokens: Optional[int] = None
    prompt_tokens: Optional[int] = None
    total_tokens: Optional[int] = None
    completion_tokens_details: Optional[TokenDetails] = None
    prompt_tokens_details: Optional[TokenDetails] = None


class ContentFilterResult(BaseModel):
    """
    Result of a content filter applied to a prompt or completion.

    Attributes:
        filtered: Whether content was filtered.
        severity: Severity level of the filtering.
        detected: Whether unsafe content was detected.
    """
    filtered: Optional[bool] = None
    severity: Optional[str] = None
    detected: Optional[bool] = None


class PromptFilterResult(BaseModel):
    """
    Holds filter evaluation results for a single prompt.

    Attributes:
        prompt_index: Index of the prompt.
        content_filter_results: Map of filter categories to results.
    """
    prompt_index: Optional[int] = None
    content_filter_results: Dict[str, ContentFilterResult]


class MetaData(BaseModel):
    """
    Rich metadata associated with a single model inference.

    Attributes:
        token_usage: Token usage summary.
        model_name: Identifier of the model variant.
        system_fingerprint: Deployment or version hash.
        id: Unique identifier for the request or sample.
        service_tier: Tier or SLA level of the request.
        prompt_filter_results: Filter results for each prompt.
        finish_reason: Reason why the generation stopped.
        logprobs: Model's log probabilities (if available).
        content_filter_results: Filters applied to the output.
        user_id: Identifier of the end-user.
        session_id: Identifier of the session.
        latency: Total response time.
        timestamp: Time of the request (UNIX).
        model_type: High-level model category (e.g., chat, completion).
    """
    token_usage: Optional[TokenUsage] = None
    model_name: Optional[str] = None
    system_fingerprint: Optional[str] = None
    id: Optional[str] = None
    service_tier: Optional[str] = None
    prompt_filter_results: Optional[List[PromptFilterResult]] = None
    finish_reason: Optional[str] = None
    logprobs: Optional[Any] = None
    content_filter_results: Optional[Dict[str, ContentFilterResult]] = None
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    latency: Optional[float] = None
    timestamp: Optional[float] = None
    model_type: Optional[str] = None

class NumericalMetric(BaseModel):
    """
    Aggregated numerical metrics for a specific time bucket.

    Attributes:
        bucket: Time window label (e.g., '2025-06-12T15:00').
        values: Mapping of metric field names to aggregated values.
    """
    bucket: str  # e.g., "2025-06-11T14:00"
    values: Dict[str, float]  # {"latency": 0.32, "token_usage.total_tokens": 59}

class CategoricalMetric(BaseModel):
    """
    Subset of fields from a metric, focused on categorical dimensions.

    Attributes:
        timestamp: UNIX timestamp of the event.
        user_id: User identifier.
        session_id: Session identifier.
        model_name: Name of the model used.
        model_type: Type or category of the model.
        finish_reason: Why the generation ended.
        id: Unique identifier of the inference.
        system_fingerprint: Deployment hash or version.
        service_tier: Tier or SLA level of the request.
    """
    timestamp: float
    user_id: Optional[str]
    session_id: Optional[str]
    model_name: Optional[str]
    model_type: Optional[str]
    finish_reason: Optional[str]
    id: Optional[str]
    system_fingerprint: Optional[str]
    service_tier: Optional[str]