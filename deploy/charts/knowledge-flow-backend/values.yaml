applicationName: knowledge-flow-backend

image:
  repository: ghcr.io/thalesgroup/fred-agent/knowledge-flow-backend
  tag: "v0.0.5"

Deployment:
  enabled: true

containers:
  name: knowledge-flow-backend

spec:
  revisionHistoryLimit: 2

serviceAccount:
  enabled: true
  name: fred-knowledge-fl-back
  annotations: {}
  labels: {}
  automount: true
  rbac:
    enabled: true
    permissions:
    # Permissions at namespace level
      namespaced:
      - apiGroups: [""]
        resources: ["pods", "configmaps", "secrets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["apps"]
        resources: ["deployments", "replicasets"]
        verbs: ["get", "list", "watch", "create", "update", "patch"]
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create"]
    
      # Permissions at cluster level
      cluster:
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list", "watch"]

ports:
  enabled: true
  data:
  - containerPort: 8111

rollingUpdate:
  maxSurge: 1

command:
  enabled: true
  # data:
  #   - /bin/sh
  #   - -c
  #   - tail -f /dev/null
  data:
  - "uvicorn"
  - "app.main:create_app"
  - "--factory"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8111"
  - "--env-file"
  - "/app/config/.env"
  - "--log-level"
  - "info"
  - "--loop"
  - "asyncio"

env:
  enabled: true
  data:
  - name: LOG_LEVEL
    value: "INFO"
  - name: CONFIG_FILE
    value: "/app/config/configuration.yaml"

# env.extraEnvVars to add variable



lifecycle:
  enabled: false

livenessProbe:
  enabled: false

readinessProbe:
  enabled: false

service:
  enabled: true
  Type: ClusterIP
  data:
    - name: "http"
      port: 8080
      targetPort: 8111
      protocol: TCP
    - name: "https"
      port: 8443
      targetPort: 8443
      protocol: TCP

ingress:
  enabled: true
  className: ""
  annotations: {}
  hosts:
    - host: knowledge-flow-backend.dev.fred.thalesgroup.com
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []

volumes:
  enabled: true
  data:
  # AWS : TODO - replace the aws volume by a real AWS configuration
  - name: aws-vol
    emptyDir:
      sizeLimit: 500Mi
  # configuration.yaml && .env since we'll mount them as a directory && kube/config
  - name: "knowledge-flow-backend-vol"
    configMap:
      name: "knowledge-flow-backend-configmap"
  # kube/config
  - name: "knowledge-flow-backend-kube-vol"
    configMap:
      name: "knowledge-flow-backend-kube-configmap"
      items:
      - key: kubeconfig
        path: kubeconfig

volumeMounts:
  enabled: true
  data:
  # aws
  - name: aws-vol
    mountPath: /home/knowledge-flow-user/.aws
  # configuration.yaml && .env
  - name: knowledge-flow-backend-vol
    mountPath: /app/config
  # kube/config
  - name: knowledge-flow-backend-kube-vol
    mountPath: /home/knowledge-flow-user/.kube/config
    subPath: kubeconfig

configuration:
  app:
    name: "Knowledge Flow Backend"
    base_url: "/knowledge-flow/v1"
    address: "0.0.0.0"
    port: 8111
    log_level: "info"
    reload: false
    reload_dir: "."
    security:
      enabled: true
      keycloak_url: "http://keycloak:8080/realms/fred"
      client_id: "app"
      authorized_origins:
      - "http://localhost:5173"
      - "http://fred.dev.fred.thalesgroup.com"
      - "https://fred.dev.fred.thalesgroup.com"

  security:
    enabled: true
    keycloak_url: "http://keycloak:8080/realms/fred"
    authorized_origins:
    - "http://localhost:5173"
    - "http://fred.dev.fred.thalesgroup.com"
    - "https://fred.dev.fred.thalesgroup.com"
  
  scheduler:
    enabled: true
    backend: "temporal"
    temporal:
      host: "localhost:7233"
      namespace: "default"
      task_queue: "ingestion"
      workflow_prefix: "pipeline"
      connect_timeout_seconds: 5

  input_processors:
    - prefix: ".pdf"
      class_path: app.core.processors.input.pdf_markdown_processor.openai_pdf_markdown_processor.OpenaiPdfMarkdownProcessor
    - prefix: ".docx"
      class_path: app.core.processors.input.docx_markdown_processor.docx_markdown_processor.DocxMarkdownProcessor
    - prefix: ".pptx"
      class_path: app.core.processors.input.pptx_markdown_processor.pptx_markdown_processor.PptxMarkdownProcessor
    - prefix: ".csv"
      class_path: app.core.processors.input.csv_tabular_processor.csv_tabular_processor.CsvTabularProcessor
    - prefix: ".txt"
      class_path: app.core.processors.input.text_markdown_processor.text_markdown_processor.TextMarkdownProcessor
    - prefix: ".md"
      class_path: app.core.processors.input.markdown_markdown_processor.markdown_markdown_processor.MarkdownMarkdownProcessor
    - prefix: ".xlsm"
      class_path: app.core.processors.input.pps_tabular_processor.pps_tabular_processor.PpsTabularProcessor

  content_storage:
    type: minio
    endpoint: http://minio:9000
    bucket_name: "knowledge-flow-content"
    secure: false

  document_sources:
    fred:
      type: push
      description: "Documents manually uploaded by users"

    local:
      type: pull
      provider: local_path
      base_path: ~/Documents/Fred
      description: "Personal local documents available for pull-mode ingestion"

    minio:
      type: pull
      provider: minio
      description: "Documents available for pull from MinIO"
      endpoint_url: localhost:9000
      bucket_name: "shared-content"
      prefix: ""
      secure: false

  metadata_storage:
    type: opensearch
    host: https://opensearch:9200
    secure: true
    verify_certs: false
    index: document-index

  tag_storage:
    type: opensearch
    host: https://opensearch:9200
    secure: true
    verify_certs: false
    index: tag-index

  prompt_storage:
    type: opensearch
    host: https://opensearch:9200
    secure: true
    verify_certs: false
    index: prompt-index

  vector_storage:
    type: opensearch
    host: https://opensearch:9200
    secure: true
    verify_certs: false
    index: vector-index-ada002
    #type: in_memory


  tabular_storage:
    type: "duckdb"
    duckdb_path: "~/.fred/knowledge-flow/tabular.duckdb"

  catalog_storage:
    type: opensearch
    host: https://opensearch:9200
    secure: true
    verify_certs: false
    index: catalog-index

  embedding:
    type: "openai"



dotenv:

  # This file contains the environment variables for the application

  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE AUTHENTICATION (for getting OAuth token)
  # -----------------------------------------------------------------------------

  AZURE_TENANT_ID: ""
  # Azure Active Directory Tenant ID for your application (OAuth 2.0 flow)

  AZURE_CLIENT_ID: ""
  # Client ID of your registered Azure AD Application (Service Principal)

  AZURE_CLIENT_SECRET: ""
  # Client Secret of your Azure AD Application

  AZURE_CLIENT_SCOPE: ""
  # OAuth2 scope for requesting tokens (typically "https://cognitiveservices.azure.com/.default")


  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE API SETTINGS
  # -----------------------------------------------------------------------------

  AZURE_API_VERSION: "2024-06-01"
  # API version used for Azure OpenAI API requests (depends on your Azure resource)


  # -----------------------------------------------------------------------------
  # ðŸ”µ API GATEWAY (APIM) SETTINGS
  # -----------------------------------------------------------------------------

  AZURE_APIM_BASE_URL: "https://trustnest.azure-api.net"
  # Base URL of your Azure API Management Gateway (APIM)
  # Example: https://company-apim-gateway.azure-api.net

  AZURE_RESOURCE_PATH_EMBEDDINGS: "/genai-aoai-inference/v1"
  # Path after base URL for Embeddings API (before /deployments/...)

  AZURE_RESOURCE_PATH_LLM: "/genai-aoai-inference/v2"
  # Path after base URL for LLM Chat API (before /deployments/...)

  AZURE_APIM_KEY: ""
  # Subscription Key required by the APIM Gateway ("TrustNest-Apim-Subscription-Key" header)

  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE OPENAI DIRECT SETTINGS (if AZURE_USE_APIM=false)
  # -----------------------------------------------------------------------------

  AZURE_OPENAI_BASE_URL: "https://your-azure-openai-resource.openai.azure.com"
  # Base URL for direct Azure OpenAI access (no APIM)

  AZURE_OPENAI_API_KEY: ""
  # Azure OpenAI API Key (directly from Azure portal, not APIM key)

  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE OPENAI DEPLOYMENT NAMES
  # -----------------------------------------------------------------------------

  AZURE_DEPLOYMENT_LLM: "gpt-4o"
  # Deployment name in Azure OpenAI for Chat LLMs (ex: GPT-4 Turbo, GPT-4o)

  AZURE_DEPLOYMENT_EMBEDDING: "fred-text-embedding-3-large"
  # Deployment name in Azure OpenAI for Embedding Models


  # -----------------------------------------------------------------------------
  # ðŸ”µ OPENAI EMBEDDING (Public API - NOT Azure)
  # -----------------------------------------------------------------------------

  OPENAI_API_KEY: ""
  # Your OpenAI API key from https://platform.openai.com/account/api-keys

  # OPENAI_API_BASE: "https://api.openai.com/v1"
  # Optional. Defaults to https://api.openai.com/v1 for OpenAI public API

  OPENAI_API_VERSION: ""
  # Leave blank for OpenAI public API (only needed for Azure)
  # Example (Azure only): "2024-06-01"

  # Example model for embeddings (default for OpenAI)
  # OPENAI_MODEL_NAME: "text-embedding-ada-002"

  # -----------------------------------------------------------------------------
  # ðŸ”µ OLLAMA SETTINGS
  # -----------------------------------------------------------------------------

  OLLAMA_API_URL: "http://localhost:11434"
  # Ollama API URL (optional)

  OLLAMA_EMBEDDING_MODEL_NAME: "snowflake-arctic-embed2:latest"
  # Model name for embeddings

  OLLAMA_VISION_MODEL_NAME: "llama3-vision:latest"
  # Model name for vision tasks (optional)


  # KEYCLOAK
  KEYCLOAK_SERVER_URL: "http://keycloak:8080"
  KEYCLOAK_REALM_NAME: "fred"
  KEYCLOAK_CLIENT_ID: "fred"

  #Â OPENSEARCH
  OPENSEARCH_USER: "admin"
  OPENSEARCH_PASSWORD: "admin123"

  #MINIO
  MINIO_ACCESS_KEY: "admin"
  MINIO_SECRET_KEY: "Azerty123_"

  #GCS
  GCS_CREDENTIALS_PATH: "/path/to/sa-key.json"
  GCS_BUCKET_NAME: "my-bucket"
  GCS_PROJECT_ID: "my-gcp-project"
  # LOCAL STORAGE
  LOCAL_CONTENT_STORAGE_PATH: "~/.fred/knowledge-flow/content-store"
  LOCAL_METADATA_STORAGE_PATH: "~/.fred/knowledge-flow/metadata-store.json"


kubeconfig:
  data:
    kubeconfig: |
      apiVersion: v1
      clusters:
      - cluster:
          certificate-authority-data: *****
          extensions:
          - extension:
              last-update: Tue, 10 Jun 2025 11:21:54 CEST
              provider: minikube.sigs.k8s.io
              version: v1.35.0
            name: cluster_info
          server: https://yyy.yyy.yyy.yyy:8443
        name: minikube
      contexts:
      - context:
          cluster: minikube
          extensions:
          - extension:
              last-update: Tue, 10 Jun 2025 11:21:54 CEST
              provider: minikube.sigs.k8s.io
              version: v1.35.0
            name: context_info
          namespace: default
          user: minikube
        name: minikube
      current-context: minikube
      kind: Config
      preferences: {}
      users:
      - name: minikube
        user:
          client-certificate-data: kkkkkk
          client-key-data: mmmmmmm