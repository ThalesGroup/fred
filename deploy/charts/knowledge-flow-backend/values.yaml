applicationName: knowledge-flow-backend

deployment:
  enabled: true

statefulset:
  enabled: false

job:
  enabled: false

##########
# Deployment/Statefulset/Job related
##########

image:
  repository: ghcr.io/thalesgroup/fred-agent/knowledge-flow-backend
  tag: "v0.0.5"

spec:
  revisionHistoryLimit: 2

imagePullSecrets: []

replicaCount: 1

rollingUpdate:
  maxSurge: 1
  maxUnavailable: 0

env:
  enabled: true
  data:
  - name: LOG_LEVEL
    value: "INFO"
  - name: CONFIG_FILE
    value: "/app/config/configuration.yaml"
# env.extraEnvVars to add variable

command:
  enabled: true
  # data:
  #   - /bin/sh
  #   - -c
  #   - tail -f /dev/null
  data:
  - "uvicorn"
  - "app.main:create_app"
  - "--factory"
  - "--host"
  - "0.0.0.0"
  - "--port"
  - "8111"
  - "--env-file"
  - "/app/config/.env"
  - "--log-level"
  - "info"
  - "--loop"
  - "asyncio"

ports:
  - name: http
    containerPort: 8111
  - name: https
    containerPort: 8443

##################
# Service related configuration
##################

service:
  enabled: true
  type: ClusterIP
  port:
    - name: "http"
      port: 8080
      targetPort: 8111
      protocol: TCP
    - name: "https"
      port: 8443
      targetPort: 8443
      protocol: TCP

##################
# Ingress related configuration
##################

ingress:
  enabled: true
  className: ""
  annotations: {}
  hosts:
    - host: knowledge-flow-backend.dev.fred.thalesgroup.com
      paths:
        - path: /
          pathType: Prefix
          servicePortName: http
  tls: []

###############
# Probes related configuration
###############

lifecycle:
  enabled: false

livenessProbe:
  enabled: false

readinessProbe:
  enabled: false

###############
# Service and RBAC related configuration
###############

serviceAccount:
  enabled: true
  name: fred-knowledge-fl-back
  annotations: {}
  labels: {}
  automount: true
  rbac:
    enabled: true
    permissions:
    # Permissions at namespace level
      namespaced:
      - apiGroups: [""]
        resources: ["pods", "configmaps", "secrets"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["apps"]
        resources: ["deployments", "replicasets"]
        verbs: ["get", "list", "watch", "create", "update", "patch"]
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create"]
    
      # Permissions at cluster level
      cluster:
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list", "watch"]

##############
# Volume and VolumeMount related configurations
##############

volumeMounts:
  enabled: true
  data:
  # aws
  - name: aws-vol
    mountPath: /home/knowledge-flow-user/.aws
  # configuration.yaml && .env
  - name: knowledge-flow-backend-vol
    mountPath: /app/config
  # kube/config
  - name: knowledge-flow-backend-kube-vol
    mountPath: /home/knowledge-flow-user/.kube/config
    subPath: kubeconfig

volumes:
  enabled: true
  data:
  # AWS : TODO - replace the aws volume by a real AWS configuration
  - name: aws-vol
    emptyDir:
      sizeLimit: 500Mi
  # configuration.yaml && .env since we'll mount them as a directory && /app/config
  - name: "knowledge-flow-backend-vol"
    configMap:
      name: "knowledge-flow-backend-configmap"
  # kube/config
  - name: "knowledge-flow-backend-kube-vol"
    configMap:
      name: "knowledge-flow-backend-kube"
      items:
      - key: kubeconfig
        path: kubeconfig

######################
# Configmaps related configuration
######################


configuration_type:
  frontend:
    enabled: false
  backend:
    enabled: true 


configuration:
  app:
    name: "Knowledge Flow Backend"
    base_url: "/knowledge-flow/v1"
    address: "0.0.0.0"
    port: 8111
    log_level: "info"
    reload: false
    reload_dir: "."
    security:
      enabled: true
      keycloak_url: "http://keycloak/realms/fred"
      client_id: "app"
      authorized_origins:
      - "http://localhost:5173"
      - "http://fred.dev.fred.thalesgroup.com"
      - "https://fred.dev.fred.thalesgroup.com"

  security:
    enabled: true
    keycloak_url: "http://keycloak/realms/fred"
    authorized_origins:
    - "http://localhost:5173"
    - "http://fred.dev.fred.thalesgroup.com"
    - "https://fred.dev.fred.thalesgroup.com"
  
  scheduler:
    enabled: true
    backend: "temporal"
    temporal:
      host: "localhost:7233"
      namespace: "default"
      task_queue: "ingestion"
      workflow_prefix: "pipeline"
      connect_timeout_seconds: 5

  input_processors:
    - prefix: ".pdf"
      class_path: app.core.processors.input.pdf_markdown_processor.openai_pdf_markdown_processor.OpenaiPdfMarkdownProcessor
    - prefix: ".docx"
      class_path: app.core.processors.input.docx_markdown_processor.docx_markdown_processor.DocxMarkdownProcessor
    - prefix: ".pptx"
      class_path: app.core.processors.input.pptx_markdown_processor.pptx_markdown_processor.PptxMarkdownProcessor
    - prefix: ".csv"
      class_path: app.core.processors.input.csv_tabular_processor.csv_tabular_processor.CsvTabularProcessor
    - prefix: ".txt"
      class_path: app.core.processors.input.text_markdown_processor.text_markdown_processor.TextMarkdownProcessor
    - prefix: ".md"
      class_path: app.core.processors.input.markdown_markdown_processor.markdown_markdown_processor.MarkdownMarkdownProcessor
    - prefix: ".xlsm"
      class_path: app.core.processors.input.pps_tabular_processor.pps_tabular_processor.PpsTabularProcessor

  content_storage:
    type: minio
    endpoint: http://minio:9000
    bucket_name: "knowledge-flow-content"
    secure: false

  document_sources:
    fred:
      type: push
      description: "Documents manually uploaded by users"

    local:
      type: pull
      provider: local_path
      base_path: ~/Documents/Fred
      description: "Personal local documents available for pull-mode ingestion"

    minio:
      type: pull
      provider: minio
      description: "Documents available for pull from MinIO"
      endpoint_url: localhost:9000
      bucket_name: "shared-content"
      prefix: ""
      secure: false

  storage:
    postgres:
      host: postgre
      port: 5432
      database: fred
      username: admin

    opensearch:
      host: https://opensearch:9200
      secure: true
      verify_certs: false
      username: admin

    tabular_store:
      type: "duckdb"
      duckdb_path: "~/.fred/knowledge-flow/tabular.duckdb"

    catalog_store:
      type: "opensearch"
      index: catalog-index

    prompt_store:
      type: "opensearch"
      index: prompt-index

    tag_store:
      type: "opensearch"
      index: tag-index

    metadata_store:
      type: "opensearch"
      index: metadata-index

    vector_store:
      type: opensearch
      index: vector-index-ada002

  embedding:
    type: "openai"


dotenv:
  # This file contains the environment variables for the application

  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE AUTHENTICATION (for getting OAuth token)
  # -----------------------------------------------------------------------------

  AZURE_TENANT_ID: ""
  # Azure Active Directory Tenant ID for your application (OAuth 2.0 flow)

  AZURE_CLIENT_ID: ""
  # Client ID of your registered Azure AD Application (Service Principal)

  AZURE_CLIENT_SECRET: ""
  # Client Secret of your Azure AD Application

  AZURE_CLIENT_SCOPE: ""
  # OAuth2 scope for requesting tokens (typically "https://cognitiveservices.azure.com/.default")


  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE API SETTINGS
  # -----------------------------------------------------------------------------

  AZURE_API_VERSION: "2024-06-01"
  # API version used for Azure OpenAI API requests (depends on your Azure resource)


  # -----------------------------------------------------------------------------
  # ðŸ”µ API GATEWAY (APIM) SETTINGS
  # -----------------------------------------------------------------------------

  AZURE_APIM_BASE_URL: "https://trustnest.azure-api.net"
  # Base URL of your Azure API Management Gateway (APIM)
  # Example: https://company-apim-gateway.azure-api.net

  AZURE_RESOURCE_PATH_EMBEDDINGS: "/genai-aoai-inference/v1"
  # Path after base URL for Embeddings API (before /deployments/...)

  AZURE_RESOURCE_PATH_LLM: "/genai-aoai-inference/v2"
  # Path after base URL for LLM Chat API (before /deployments/...)

  AZURE_APIM_KEY: ""
  # Subscription Key required by the APIM Gateway ("TrustNest-Apim-Subscription-Key" header)

  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE OPENAI DIRECT SETTINGS (if AZURE_USE_APIM=false)
  # -----------------------------------------------------------------------------

  AZURE_OPENAI_BASE_URL: "https://your-azure-openai-resource.openai.azure.com"
  # Base URL for direct Azure OpenAI access (no APIM)

  AZURE_OPENAI_API_KEY: ""
  # Azure OpenAI API Key (directly from Azure portal, not APIM key)

  # -----------------------------------------------------------------------------
  # ðŸ”µ AZURE OPENAI DEPLOYMENT NAMES
  # -----------------------------------------------------------------------------

  AZURE_DEPLOYMENT_LLM: "gpt-4o"
  # Deployment name in Azure OpenAI for Chat LLMs (ex: GPT-4 Turbo, GPT-4o)

  AZURE_DEPLOYMENT_EMBEDDING: "fred-text-embedding-3-large"
  # Deployment name in Azure OpenAI for Embedding Models


  # -----------------------------------------------------------------------------
  # ðŸ”µ OPENAI EMBEDDING (Public API - NOT Azure)
  # -----------------------------------------------------------------------------

  OPENAI_API_KEY: ""
  # Your OpenAI API key from https://platform.openai.com/account/api-keys

  # OPENAI_API_BASE: "https://api.openai.com/v1"
  # Optional. Defaults to https://api.openai.com/v1 for OpenAI public API

  OPENAI_API_VERSION: ""
  # Leave blank for OpenAI public API (only needed for Azure)
  # Example (Azure only): "2024-06-01"

  # Example model for embeddings (default for OpenAI)
  # OPENAI_MODEL_NAME: "text-embedding-ada-002"

  # -----------------------------------------------------------------------------
  # ðŸ”µ OLLAMA SETTINGS
  # -----------------------------------------------------------------------------

  OLLAMA_API_URL: "http://localhost:11434"
  # Ollama API URL (optional)

  OLLAMA_EMBEDDING_MODEL_NAME: "snowflake-arctic-embed2:latest"
  # Model name for embeddings

  OLLAMA_VISION_MODEL_NAME: "llama3-vision:latest"
  # Model name for vision tasks (optional)


  # KEYCLOAK
  KEYCLOAK_SERVER_URL: "http://keycloak:8080"
  KEYCLOAK_REALM_NAME: "fred"
  KEYCLOAK_CLIENT_ID: "fred"

  #Â OPENSEARCH
  OPENSEARCH_USER: "admin"
  OPENSEARCH_PASSWORD: "admin123"

  #MINIO
  MINIO_ACCESS_KEY: "admin"
  MINIO_SECRET_KEY: "Azerty123_"

  #GCS
  GCS_CREDENTIALS_PATH: "/path/to/sa-key.json"
  GCS_BUCKET_NAME: "my-bucket"
  GCS_PROJECT_ID: "my-gcp-project"
  # LOCAL STORAGE
  LOCAL_CONTENT_STORAGE_PATH: "~/.fred/knowledge-flow/content-store"
  LOCAL_METADATA_STORAGE_PATH: "~/.fred/knowledge-flow/metadata-store.json"





kubeconfig:
  enabled: true
  data:
    kubeconfig: |
      apiVersion: v1
      clusters:
      - cluster:
          certificate-authority-data: *****
          extensions:
          - extension:
              last-update: Tue, 10 Jun 2025 11:21:54 CEST
              provider: minikube.sigs.k8s.io
              version: v1.35.0
            name: cluster_info
          server: https://yyy.yyy.yyy.yyy:8443
        name: minikube
      contexts:
      - context:
          cluster: minikube
          extensions:
          - extension:
              last-update: Tue, 10 Jun 2025 11:21:54 CEST
              provider: minikube.sigs.k8s.io
              version: v1.35.0
            name: context_info
          namespace: default
          user: minikube
        name: minikube
      current-context: minikube
      kind: Config
      preferences: {}
      users:
      - name: minikube
        user:
          client-certificate-data: kkkkkk
          client-key-data: mmmmmmm